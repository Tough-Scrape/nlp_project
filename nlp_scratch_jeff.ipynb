{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/search?o=desc&p=1&q=stars%3A%3E1&s=stars&type=Repositories'\n",
    "headers = {'User-Agent': \"Codeup Data Science Student\"}\n",
    "response = get(url,headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_list = soup.find('ul',class_='repo-list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = repo_list.find_all(href=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = links[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,w in enumerate(links):\n",
    "    print(links[index]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [link['href'] for link in links if not re.match(r'^/topics',link['href']) and not re.match(r'^https',link['href']) and link['href'].count('/') < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = list(range(1,3))\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/search?o=desc&p=2&q=stars%3A%3E1&s=stars&type=Repositories'\n",
    "headers = {'User-Agent': \"Codeup Data Science Student\"}\n",
    "response = get(url,headers)\n",
    "soup = BeautifulSoup(response.text)\n",
    "repo_list = soup.find('ul',class_='repo-list')\n",
    "links = repo_list.find_all(href=True)\n",
    "repo_links = [link['href'] for link in links if not re.match(r'^/topics',link['href'])\\\n",
    "     and not re.match(r'^https',link['href'])\\\n",
    "     and link['href'].count('/') < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://github.com/search?o=desc&p=1&q=stars%3A%3E1&s=stars&type=Repositories'\n",
    "f\"fdsffdsfsdfds{pages[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = list(range(1,3))\n",
    "page_urls = []\n",
    "for page in pages:\n",
    "    p = f'https://github.com/search?o=desc&p={page}&q=stars%3A%3E1&s=stars&type=Repositories'\n",
    "    page_urls.append(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(start_page,stop_page):\n",
    "    pages = list(range(start_page,stop_page+1))\n",
    "    page_urls = []\n",
    "    for page in pages:\n",
    "        p = f'https://github.com/search?o=desc&p={page}&q=stars%3A%3E1&s=stars&type=Repositories'\n",
    "        page_urls.append(p)\n",
    "\n",
    "    repo_links_all = []\n",
    "    for page in page_urls:\n",
    "        url = page\n",
    "        headers  = {'User-Agent' : 'Codeup Data Science Student'} #user-agent to decrease chance of being rejected by github\n",
    "        response = get(url,headers)\n",
    "        soup = BeautifulSoup(response.text) #created a BS object\n",
    "        repo_list = soup.find('ul', class_='repo-list') #find section of text of interest\n",
    "        links = repo_list.find_all(href = True) #isolate the 'href's \n",
    "        repo_links= [link['href'] for link in links if not re.match(r'^/topics',link['href']) and not re.match(r'^https',link['href'])\\\n",
    "                 and link['href'].count('/') < 3] #further pare down list by excluding anything that begins with /topics, https or more than 2 forward slashes\n",
    "        repo_links_all.extend(repo_links)\n",
    "        return repo_links_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-1e9d2f85713f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0murls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-14347621a650>\u001b[0m in \u001b[0;36mget_urls\u001b[0;34m(start_page, stop_page)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#created a BS object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mrepo_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ul'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'repo-list'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#find section of text of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepo_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#isolate the 'href's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         repo_links= [link['href'] for link in links if not re.match(r'^/topics',link['href']) and not re.match(r'^https',link['href'])\\\n\u001b[1;32m     17\u001b[0m                  and link['href'].count('/') < 3] #further pare down list by excluding anything that begins with /topics, https or more than 2 forward slashes\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "urls = get_urls(1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls2 = get_urls(8,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/django/django',\n",
       " '/MisterBooo/LeetCodeAnimation',\n",
       " '/shadowsocks/shadowsocks-windows',\n",
       " '/chrislgarry/Apollo-11',\n",
       " '/jakubroztocil/httpie',\n",
       " '/rails/rails',\n",
       " '/typicode/json-server',\n",
       " '/spring-projects/spring-boot',\n",
       " '/storybookjs/storybook',\n",
       " '/h5bp/html5-boilerplate']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/search?p=2&q=stars%3A%3E0&s=stars&type=Repositories' #page 1 of repository of interest (star)\n",
    "headers  = {'User-Agent' : 'Codeup Data Science Student'} #user-agent to decrease chance of being rejected by github\n",
    "response = get(url,headers)\n",
    "soup = BeautifulSoup(response.text) #created a BS object\n",
    "repo_list = soup.find('ul', class_='repo-list') #find section of text of interest\n",
    "links = repo_list.find_all(href = True) #isolate the 'href's \n",
    "repo_links= [link['href'] for link in links if not re.match(r'^/topics',link['href']) and not re.match(r'^https',link['href'])\\\n",
    "         and link['href'].count('/') < 3] #further pare down list by excluding anything that begins with /topics, https or more than 2 forward slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = urls.extend(urls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/vuejs/vue\"\n",
    "headers  = {'User-Agent' : 'Codeup Data Science Student'} #user-agent to decrease chance of being rejected by github\n",
    "response = get(url,headers)\n",
    "soup = BeautifulSoup(response.text) #created a BS object\n",
    "repo_list = soup.find('ul', class_='repo-list') #find section of text of interest\n",
    "links = repo_list.find_all(href = True) #isolate the 'href's \n",
    "repo_links= [link['href'] for link in links if not re.match(r'^/topics',link['href']) and not re.match(r'^https',link['href'])\\\n",
    "         and link['href'].count('/') < 3] #further pare down list by excluding anything that begins with /topics, https or more than 2 forward slashes\n",
    "repo_links_all.extend(repo_links)\n",
    "return repo_links_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/Zillow-SJ/Cluster_Zillow\"\n",
    "headers  = {'User-Agent' : 'Codeup Data Science Student'} #user-agent to decrease chance of being rejected by github\n",
    "response = get(url,headers)\n",
    "soup = BeautifulSoup(response.text) #created a BS object\n",
    "readme_url = soup.find('a',title='README.md')['href']\n",
    "readme_url = f'https://github.com{readme_url}'\n",
    "response2 = get(readme_url,headers)\n",
    "soup2 = BeautifulSoup(response2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls2 = [url[1:] for url in urls2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "A module for obtaining repo readme and language data from the github API.\n",
    "\n",
    "Before using this module, read through it, and follow the instructions marked\n",
    "TODO.\n",
    "\n",
    "After doing so, run it like this:\n",
    "\n",
    "    python acquire.py\n",
    "\n",
    "To create the `data.json` file that contains the data.\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List\n",
    "import requests\n",
    "\n",
    "from env import github_token\n",
    "\n",
    "# TODO: Make a github personal access token.\n",
    "#     1. Go here and generate a personal access token https://github.com/settings/tokens\n",
    "#     2. Save it in your env.py file under the variable `github_token`\n",
    "# TODO: Replace YOUR_GITHUB_USERNAME below with your github username.\n",
    "# TODO: Add more repositories to the `repos` list.\n",
    "\n",
    "repos = urls2\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"token {github_token}\",\n",
    "    \"User-Agent\": \"JefferyRoeder\",\n",
    "}\n",
    "\n",
    "if (\n",
    "    headers[\"Authorization\"] == \"token \"\n",
    "    or headers[\"User-Agent\"] == \"YOUR_GITHUB_USERNAME\"\n",
    "):\n",
    "    raise Exception(\n",
    "        \"You need to follow the instructions marked TODO in this script before trying to use it\"\n",
    "    )\n",
    "\n",
    "\n",
    "def github_api_request(url: str) -> requests.Response:\n",
    "    return requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "def get_repo_language(repo: str) -> str:\n",
    "    url = f\"https://api.github.com/repos/{repo}\"\n",
    "    return github_api_request(url).json()[\"language\"]\n",
    "\n",
    "\n",
    "def get_repo_contents(repo: str) -> List[Dict[str, str]]:\n",
    "    url = f\"https://api.github.com/repos/{repo}/contents/\"\n",
    "    return github_api_request(url).json()\n",
    "\n",
    "\n",
    "def get_readme_download_url(files: List[Dict[str, str]]) -> str:\n",
    "    \"\"\"\n",
    "    Takes in a response from the github api that lists\n",
    "    the files in a repo and returns the url that can be\n",
    "    used to download the repo's README file.\n",
    "    \"\"\"\n",
    "    for file in files:\n",
    "        if file[\"name\"].lower().startswith(\"readme\"):\n",
    "            return file[\"download_url\"]\n",
    "\n",
    "\n",
    "def process_repo(repo: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Takes a repo name like \"gocodeup/codeup-setup-script\" and returns\n",
    "    a dictionary with the language of the repo and the readme contents.\n",
    "    \"\"\"\n",
    "    contents = get_repo_contents(repo)\n",
    "    return {\n",
    "        \"repo\": repo,\n",
    "        \"language\": get_repo_language(repo),\n",
    "        \"readme_contents\": requests.get(get_readme_download_url(contents)).text,\n",
    "    }\n",
    "\n",
    "\n",
    "def scrape_github_data():\n",
    "    \"\"\"\n",
    "    Loop through all of the repos and process them. Saves the data in\n",
    "    `data.json`.\n",
    "    \"\"\"\n",
    "    data = [process_repo(repo) for repo in repos]\n",
    "    json.dump(data, open(\"data.json\", \"w\"))\n",
    "\n",
    "\n",
    "\n",
    "x = scrape_github_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>repo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python</td>\n",
       "      <td>======\\nDjango\\n======\\n\\nDjango is a high-lev...</td>\n",
       "      <td>django/django</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Java</td>\n",
       "      <td>![LeetCode Animation All in One](https://uploa...</td>\n",
       "      <td>MisterBooo/LeetCodeAnimation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C#</td>\n",
       "      <td>&lt;img src=\"shadowsocks-csharp/Resources/ssw128....</td>\n",
       "      <td>shadowsocks/shadowsocks-windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assembly</td>\n",
       "      <td>&lt;div dir=\"RTL\"&gt;\\n\\n# أبولو 11\\n[![NASA][1]][2]...</td>\n",
       "      <td>chrislgarry/Apollo-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python</td>\n",
       "      <td>HTTPie: a CLI, cURL-like tool for humans\\n####...</td>\n",
       "      <td>jakubroztocil/httpie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ruby</td>\n",
       "      <td># Welcome to Rails\\n\\n## What's Rails?\\n\\nRail...</td>\n",
       "      <td>rails/rails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td># JSON Server [![](https://travis-ci.org/typic...</td>\n",
       "      <td>typicode/json-server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Java</td>\n",
       "      <td>= Spring Boot image:https://ci.spring.io/api/v...</td>\n",
       "      <td>spring-projects/spring-boot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TypeScript</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n  &lt;a href=\"https://storybo...</td>\n",
       "      <td>storybookjs/storybook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td># [HTML5 Boilerplate](https://html5boilerplate...</td>\n",
       "      <td>h5bp/html5-boilerplate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language                                    readme_contents  \\\n",
       "0      Python  ======\\nDjango\\n======\\n\\nDjango is a high-lev...   \n",
       "1        Java  ![LeetCode Animation All in One](https://uploa...   \n",
       "2          C#  <img src=\"shadowsocks-csharp/Resources/ssw128....   \n",
       "3    Assembly  <div dir=\"RTL\">\\n\\n# أبولو 11\\n[![NASA][1]][2]...   \n",
       "4      Python  HTTPie: a CLI, cURL-like tool for humans\\n####...   \n",
       "5        Ruby  # Welcome to Rails\\n\\n## What's Rails?\\n\\nRail...   \n",
       "6  JavaScript  # JSON Server [![](https://travis-ci.org/typic...   \n",
       "7        Java  = Spring Boot image:https://ci.spring.io/api/v...   \n",
       "8  TypeScript  <p align=\"center\">\\n  <a href=\"https://storybo...   \n",
       "9  JavaScript  # [HTML5 Boilerplate](https://html5boilerplate...   \n",
       "\n",
       "                              repo  \n",
       "0                    django/django  \n",
       "1     MisterBooo/LeetCodeAnimation  \n",
       "2  shadowsocks/shadowsocks-windows  \n",
       "3            chrislgarry/Apollo-11  \n",
       "4             jakubroztocil/httpie  \n",
       "5                      rails/rails  \n",
       "6             typicode/json-server  \n",
       "7      spring-projects/spring-boot  \n",
       "8            storybookjs/storybook  \n",
       "9           h5bp/html5-boilerplate  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
